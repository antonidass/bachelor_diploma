\addcontentsline{toc}{chapter}{ПРИЛОЖЕНИЕ А}

\chapter*{ПРИЛОЖЕНИЕ А}

\begin{lstlisting}[label=code:model, language=python, caption={Модель нейронной сети}]
    class EagerNet(torch.nn.Module):
    def __init__(self, n_input, n_output, n_layers, layer_size, device):
        super(EagerNet, self).__init__()
        self.n_output = n_output
        self.n_layers = n_layers 
        self.beginning = torch.nn.Linear(n_input, layer_size+n_output).to(device)
        self.middle = torch.nn.Sequential(*[torch.nn.Linear(layer_size, layer_size+n_output).to(device) for _ in range(n_layers)])
        self.end = torch.nn.Linear(layer_size, n_output).to(device) 
    
    def forward(self, x):
        all_outputs = []
        all_xs = []
        output_beginning = self.beginning(x) 
        all_xs.append(x)
    
        x = torch.nn.functional.leaky_relu(output_beginning[:,:-self.n_output])
    
        all_outputs.append(output_beginning[:,-self.n_output:])
    
        for current_layer in self.middle:
            current_output = current_layer(x)
            all_xs.append(x)
            x = torch.nn.functional.leaky_relu(current_output[:,:-self.n_output])
            all_outputs.append(current_output[:,-self.n_output:])
    
        all_xs.append(x)
        output_end = self.end(x)
        all_outputs.append(output_end)
    
        return all_outputs, all_xs
\end{lstlisting}


\begin{lstlisting}[label=code:model, language=python, caption={Функция классификации}]
def multiclass_predict(net, dataset, device, n_outputs):
    batchSize = 1
    loader = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=False)

    y_pred_list = [[] for _ in range(n_outputs)]
    y_list = []
    with torch.no_grad():
        net.eval()
        for data, labels in tqdm(loader):			
            X_batch = data.to(device)
            outputs, _ = net(X_batch)

            for output_index, y_test_pred in enumerate(outputs):
                y_pred_softmax = torch.log_softmax(y_test_pred, dim = 1)
                _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)
                y_pred_list[output_index].append(y_pred_tags.cpu().numpy())

            _, labels = torch.max(labels, dim = 1)
            y_list.append(labels.cpu().numpy())


    y_list = [a.squeeze().tolist() for a in y_list]
    for i, output in enumerate(y_pred_list):
            y_pred_list[i] = [a.squeeze().tolist() for a in output]
    
    return y_pred_list[-1]
\end{lstlisting}